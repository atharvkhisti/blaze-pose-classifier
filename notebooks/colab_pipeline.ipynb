{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a88c35c",
   "metadata": {},
   "source": [
    "# Olym+ BlazePose Pipeline (Colab)\n",
    "End-to-end: install → mount Drive → datasets → landmarks → features → windows → train → reps → figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Setup\n",
    "!pip install mediapipe opencv-python-headless pandas numpy scikit-learn xgboost matplotlib seaborn tqdm pyarrow joblib -q\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "BASE='/content/drive/MyDrive/olymp_project'\n",
    "for d in ['data/mmfit_videos','data/kaggle_pushup','landmarks','features','models','results']:\n",
    "    os.makedirs(f'{BASE}/{d}', exist_ok=True)\n",
    "print('Workdir:', BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150123d",
   "metadata": {},
   "source": [
    "## 1) Datasets\n",
    "- Upload videos to Drive folders:\n",
    "  - mmfit videos → /content/drive/MyDrive/olymp_project/data/mmfit_videos/\n",
    "  - kaggle pushup → /content/drive/MyDrive/olymp_project/data/kaggle_pushup/\n",
    "- Optional: use Kaggle API (place kaggle.json in Drive root and run below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle optional\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/ 2>/dev/null || true\n",
    "!chmod 600 ~/.kaggle/kaggle.json 2>/dev/null || true\n",
    "# Example: replace <dataset-slug> with the dataset you want\n",
    "# !kaggle datasets download -d <dataset-slug> -p $BASE/data/kaggle_pushup --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8862c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Landmark extraction (MediaPipe BlazePose)\n",
    "import cv2, mediapipe as mp, os, csv, glob, tqdm\n",
    "mp_pose = mp.solutions.pose\n",
    "def extract_landmarks_from_video(video_path, out_csv, sample_rate=2):\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_i = 0\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    with open(out_csv, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            header = ['video','frame','timestamp','width','height']\n",
    "            for i in range(33): header += [f'lm{i}_x',f'lm{i}_y',f'lm{i}_z',f'lm{i}_vis']\n",
    "            writer.writerow(header)\n",
    "        while cap.isOpened():\n",
    "            ret,frame = cap.read()\n",
    "            if not ret: break\n",
    "            if frame_i % sample_rate == 0:\n",
    "                h,w = frame.shape[:2]\n",
    "                img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                res = pose.process(img)\n",
    "                row = [os.path.basename(video_path), frame_i, cap.get(cv2.CAP_PROP_POS_MSEC), w, h]\n",
    "                if res.pose_landmarks:\n",
    "                    for lm in res.pose_landmarks.landmark:\n",
    "                        row += [lm.x, lm.y, lm.z, lm.visibility]\n",
    "                else:\n",
    "                    row += [None]*(33*4)\n",
    "                writer.writerow(row)\n",
    "            frame_i += 1\n",
    "    cap.release()\n",
    "base=f'{BASE}/data'\n",
    "out_dir=f'{BASE}/landmarks'\n",
    "for dataset_folder in ['mmfit_videos','kaggle_pushup']:\n",
    "    infolder=os.path.join(base,dataset_folder)\n",
    "    outcsv=os.path.join(out_dir,f'{dataset_folder}_landmarks.csv')\n",
    "    vids=glob.glob(os.path.join(infolder,'**','*.mp4'), recursive=True)\n",
    "    print('Processing', len(vids), 'videos in', infolder)\n",
    "    for v in tqdm.tqdm(vids):\n",
    "        extract_landmarks_from_video(v, outcsv, sample_rate=2)\n",
    "print('Done landmarks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Feature engineering (per-frame)\n",
    "import pandas as pd, numpy as np, math\n",
    "LANDMARK_CSV=f'{BASE}/landmarks/mmfit_videos_landmarks.csv'\n",
    "OUT_PKL=f'{BASE}/features/mmfit_features.pkl'\n",
    "df=pd.read_csv(LANDMARK_CSV)\n",
    "df=df.dropna(subset=['lm0_x']).reset_index(drop=True)\n",
    "def get_landmarks(row):\n",
    "    lm=[]\n",
    "    for i in range(33):\n",
    "        lm.append((row.get(f'lm{i}_x',np.nan), row.get(f'lm{i}_y',np.nan), row.get(f'lm{i}_z',np.nan)))\n",
    "    return np.array(lm,float)\n",
    "def angle_between(a,b,c):\n",
    "    ba=a-b; bc=c-b\n",
    "    if np.any(np.isnan(ba)) or np.any(np.isnan(bc)): return np.nan\n",
    "    cosang = float(np.dot(ba,bc)/(np.linalg.norm(ba)*np.linalg.norm(bc)+1e-9))\n",
    "    cosang = max(-1., min(1., cosang))\n",
    "    return math.degrees(math.acos(cosang))\n",
    "idx={'nose':0,'l_sh':11,'r_sh':12,'l_el':13,'r_el':14,'l_wr':15,'r_wr':16,'l_hip':23,'r_hip':24,'l_knee':25,'r_knee':26,'l_ank':27,'r_ank':28}\n",
    "rows=[]\n",
    "for _,r in df.iterrows():\n",
    "    lm=get_landmarks(r); w,h=r['width'], r['height']; pts=lm.copy(); pts[:,0]*=w; pts[:,1]*=h\n",
    "    l_elbow=angle_between(pts[idx['l_sh']], pts[idx['l_el']], pts[idx['l_wr']])\n",
    "    r_elbow=angle_between(pts[idx['r_sh']], pts[idx['r_el']], pts[idx['r_wr']])\n",
    "    l_knee=angle_between(pts[idx['l_hip']], pts[idx['l_knee']], pts[idx['l_ank']])\n",
    "    r_knee=angle_between(pts[idx['r_hip']], pts[idx['r_knee']], pts[idx['r_ank']])\n",
    "    l_hip=angle_between(pts[idx['l_sh']], pts[idx['l_hip']], pts[idx['l_knee']])\n",
    "    r_hip=angle_between(pts[idx['r_sh']], pts[idx['r_hip']], pts[idx['r_knee']])\n",
    "    mid_hip=(pts[idx['l_hip']]+pts[idx['r_hip']])/2.0; nose=pts[idx['nose']]\n",
    "    body_tilt=(np.degrees(np.arctan2((nose-mid_hip)[1], (nose-mid_hip)[0])) if not np.any(np.isnan(nose-mid_hip)) else np.nan)\n",
    "    def dist(a,b):\n",
    "        if np.any(np.isnan(a[:2])) or np.any(np.isnan(b[:2])): return np.nan\n",
    "        return float(np.linalg.norm(a[:2]-b[:2]))\n",
    "    shoulder_width=dist(pts[idx['l_sh']], pts[idx['r_sh']]); hip_width=dist(pts[idx['l_hip']], pts[idx['r_hip']])\n",
    "    torso_len=dist((pts[idx['l_sh']]+pts[idx['r_sh']])/2.0, mid_hip); arm_len=dist(pts[idx['l_sh']], pts[idx['l_wr']])\n",
    "    rows.append({'video':r['video'],'frame':int(r['frame']),'timestamp':float(r['timestamp']),\n",
    "                 'l_elbow':l_elbow,'r_elbow':r_elbow,'l_knee':l_knee,'r_knee':r_knee,'l_hip':l_hip,'r_hip':r_hip,\n",
    "                 'body_tilt':body_tilt,'ratio_sh_hip': shoulder_width/(hip_width+1e-6) if not np.isnan(shoulder_width) and not np.isnan(hip_width) else np.nan,\n",
    "                 'ratio_arm_torso': arm_len/(torso_len+1e-6) if not np.isnan(arm_len) and not np.isnan(torso_len) else np.nan,\n",
    "                 'shoulder_width': shoulder_width, 'hip_width': hip_width})\n",
    "feat_df=pd.DataFrame(rows)\n",
    "feat_df.to_pickle(OUT_PKL); print('Saved', OUT_PKL, feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef06737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Windowing + labels\n",
    "import pandas as pd, numpy as np, os\n",
    "feat_df=pd.read_pickle(f'{BASE}/features/mmfit_features.pkl')\n",
    "labels_csv=f'{BASE}/data/video_labels.csv'\n",
    "if not os.path.exists(labels_csv):\n",
    "    with open(labels_csv,'w') as f: f.write('video,exercise,form\n",
    "example1.mp4,biceps,correct\n",
    "')\n",
    "labels=pd.read_csv(labels_csv)\n",
    "feat_df=feat_df.merge(labels, on='video', how='left')\n",
    "FPS=30; WINDOW_SEC=1.5; WINDOW_SIZE=int(WINDOW_SEC*FPS/2); STEP=WINDOW_SIZE//2\n",
    "rows=[]\n",
    "num_cols=['l_elbow','r_elbow','l_knee','r_knee','l_hip','r_hip','body_tilt','ratio_sh_hip','ratio_arm_torso']\n",
    "for v, vdf in feat_df.groupby('video'):\n",
    "  vdf=vdf.sort_values('frame').reset_index(drop=True)\n",
    "  for s in range(0, len(vdf)-WINDOW_SIZE+1, STEP):\n",
    "    w=vdf.iloc[s:s+WINDOW_SIZE]; agg={'video':v,'start_idx':int(w.iloc[0]['frame']),'exercise':w.get('exercise',pd.Series([None])).iloc[0],'form':w.get('form',pd.Series([None])).iloc[0]}\n",
    "    for c in num_cols:\n",
    "      agg[f'{c}_mean']=float(w[c].mean()); agg[f'{c}_std']=float(w[c].std()); agg[f'{c}_min']=float(w[c].min()); agg[f'{c}_max']=float(w[c].max())\n",
    "    rows.append(agg)\n",
    "win_df=pd.DataFrame(rows)\n",
    "win_df.to_pickle(f'{BASE}/features/mmfit_windows.pkl'); win_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c948b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Train RandomForest baseline vs enhanced\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib, os\n",
    "df=pd.read_pickle(f'{BASE}/features/mmfit_windows.pkl').dropna(subset=['exercise']).reset_index(drop=True)\n",
    "le=LabelEncoder(); df['y']=le.fit_transform(df['exercise'])\n",
    "videos=df['video'].unique(); tr,te=train_test_split(videos, test_size=0.2, random_state=42)\n",
    "trdf=df[df.video.isin(tr)]; tedf=df[df.video.isin(te)]\n",
    "baseline=['l_elbow_mean','r_elbow_mean','l_knee_mean','r_knee_mean','l_hip_mean','r_hip_mean']\n",
    "enh=baseline+['body_tilt_mean','ratio_sh_hip_mean','ratio_arm_torso_mean']+[c for c in df.columns if c.endswith('_std')]\n",
    "rfb=RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1).fit(trdf[baseline].fillna(0), trdf['y'])\n",
    "rfe=RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1).fit(trdf[enh].fillna(0), trdf['y'])\n",
    "pb=rfb.predict(tedf[baseline].fillna(0)); pe=rfe.predict(tedf[enh].fillna(0))\n",
    "print('Baseline:\n",
    "', classification_report(tedf['y'], pb, target_names=le.classes_))\n",
    "print('Enhanced:\n",
    "', classification_report(tedf['y'], pe, target_names=le.classes_))\n",
    "cm_b=confusion_matrix(tedf['y'], pb); cm_e=confusion_matrix(tedf['y'], pe)\n",
    "plt.figure(figsize=(10,4)); plt.subplot(1,2,1); sns.heatmap(cm_b, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_); plt.title('Baseline')\n",
    "plt.subplot(1,2,2); sns.heatmap(cm_e, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_); plt.title('Enhanced'); plt.tight_layout()\n",
    "plt.savefig(f'{BASE}/results/confusion_comparison.png', dpi=200)\n",
    "joblib.dump(rfb, f'{BASE}/models/rf_baseline.pkl'); joblib.dump(rfe, f'{BASE}/models/rf_enhanced.pkl')\n",
    "print('Saved models and figures to Drive/results & Drive/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d00828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Rep counting example (biceps using left elbow)\n",
    "import pandas as pd\n",
    "ff=pd.read_pickle(f'{BASE}/features/mmfit_features.pkl')\n",
    "v=ff['video'].unique()[0] if len(ff)>0 else None\n",
    "def count(ang, down=50, up=160):\n",
    "  s='up'; c=0\n",
    "  for a in ang:\n",
    "    if s=='up' and a<down: s='down'\n",
    "    elif s=='down' and a>up: s='up'; c+=1\n",
    "  return c\n",
    "if v:\n",
    "  vdf=ff[ff.video==v].sort_values('frame'); print('Video:', v, 'Reps:', count(vdf['l_elbow'].fillna(method='ffill').fillna(method='bfill').values))\n",
    "else:\n",
    "  print('No features yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01528901",
   "metadata": {},
   "source": [
    "# BlazePose Exercise Classifier — Google Colab Pipeline\n",
    "\n",
    "Follow the cells top-to-bottom. Use GPU runtime if you plan to process many videos, though CPU is fine for this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ca977",
   "metadata": {},
   "source": [
    "## 1. Select Runtime and Verify Environment\n",
    "\n",
    "- In Colab, go to Runtime → Change runtime type → Hardware accelerator: GPU (optional).\n",
    "- Run the cell below to print Python and platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check\n",
    "import sys, platform\n",
    "print(sys.version)\n",
    "print(platform.platform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfdd0e",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies\n",
    "This installs the core libraries used in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mediapipe opencv-python-headless numpy pandas scikit-learn matplotlib seaborn tqdm joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395709f5",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive\n",
    "This persists datasets and outputs so they survive Colab sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d864e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "BASE_DIR = '/content/drive/MyDrive/blazepose-classifier'\n",
    "SRC_DIR = f'{BASE_DIR}/src'\n",
    "DATA_DIR = f'{BASE_DIR}/data'\n",
    "LANDMARKS_DIR = f'{BASE_DIR}/landmarks'\n",
    "FEATURES_DIR = f'{BASE_DIR}/features'\n",
    "MODELS_DIR = f'{BASE_DIR}/models'\n",
    "RESULTS_DIR = f'{BASE_DIR}/results'\n",
    "\n",
    "for d in [BASE_DIR, SRC_DIR, DATA_DIR, LANDMARKS_DIR, FEATURES_DIR, MODELS_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print('BASE_DIR =', BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b21c22",
   "metadata": {},
   "source": [
    "## 4. Acquire Project Code (clone/upload)\n",
    "Place your project files in Drive under BASE_DIR. If this is your first run, upload the `src/` folder to `blazepose-classifier/src` or clone your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3676a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that required scripts are present; if not, create quick copies from this notebook (optional)\n",
    "import os\n",
    "required_files = ['extract_landmarks.py','feature_engineering.py','windowing.py','train_models.py','rep_counting.py']\n",
    "missing = [f for f in required_files if not os.path.exists(f'{SRC_DIR}/{f}')]\n",
    "print('Missing in SRC_DIR:', missing)\n",
    "print('SRC_DIR =', SRC_DIR)\n",
    "print('DATA_DIR =', DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f80a0",
   "metadata": {},
   "source": [
    "## 5. (Option A) Extract Landmarks from raw videos\n",
    "If you uploaded `.mp4` videos into Drive under `data/mmfit_videos` or `data/kaggle_pushup`, run this. Skip if you only have MM-Fit `pose_2d.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Extract from videos (requires SRC_DIR/extract_landmarks.py present)\n",
    "!python {SRC_DIR}/extract_landmarks.py --input {DATA_DIR}/mmfit_videos {DATA_DIR}/kaggle_pushup --output {LANDMARKS_DIR} --name mmfit_videos_landmarks.csv --sample-rate 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50b8a3",
   "metadata": {},
   "source": [
    "## 6. (Option B) Convert MM-Fit pose_2d.npy → landmarks CSV\n",
    "If you have MM-Fit `wXX/wXX_pose_2d.npy`, convert them into the same landmarks CSV expected by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44253b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Convert pose_2d.npy to landmarks CSV using an inline converter\n",
    "import os, csv, glob\n",
    "import numpy as np\n",
    "\n",
    "BLAZEPOSE_SIZE = 33\n",
    "COCO17 = {'nose':0,'left_eye':1,'right_eye':2,'left_ear':3,'right_ear':4,'left_shoulder':5,'right_shoulder':6,'left_elbow':7,'right_elbow':8,'left_wrist':9,'right_wrist':10,'left_hip':11,'right_hip':12,'left_knee':13,'right_knee':14,'left_ankle':15,'right_ankle':16}\n",
    "OPENPOSE25 = {'nose':0,'neck':1,'right_shoulder':2,'right_elbow':3,'right_wrist':4,'left_shoulder':5,'left_elbow':6,'left_wrist':7,'mid_hip':8,'right_hip':9,'right_knee':10,'right_ankle':11,'left_hip':12,'left_knee':13,'left_ankle':14,'right_eye':15,'left_eye':16,'right_ear':17,'left_ear':18}\n",
    "TARGET = {'nose':0,'left_shoulder':11,'right_shoulder':12,'left_elbow':13,'right_elbow':14,'left_wrist':15,'right_wrist':16,'left_hip':23,'right_hip':24,'left_knee':25,'right_knee':26,'left_ankle':27,'right_ankle':28}\n",
    "SCHEMAS = {'coco17':COCO17,'openpose25':OPENPOSE25}\n",
    "\n",
    "def infer_schema_from_npy(path):\n",
    "    arr = np.load(path)\n",
    "    if arr.ndim == 3:\n",
    "        K = arr.shape[1]\n",
    "    elif arr.ndim == 2:\n",
    "        K = arr.shape[1]//2\n",
    "    else:\n",
    "        return None\n",
    "    if K == 17:\n",
    "        return 'coco17'\n",
    "    if K == 25:\n",
    "        return 'openpose25'\n",
    "    return None\n",
    "\n",
    "def build_mapping(schema):\n",
    "    src = SCHEMAS[schema]\n",
    "    mapping = {}\n",
    "    for name in TARGET:\n",
    "        if name in src:\n",
    "            mapping[src[name]] = TARGET[name]\n",
    "    return mapping\n",
    "\n",
    "def write_header(w):\n",
    "    header=['video','frame','timestamp','width','height']\n",
    "    for i in range(BLAZEPOSE_SIZE):\n",
    "        header += [f'lm{i}_x',f'lm{i}_y',f'lm{i}_z',f'lm{i}_vis']\n",
    "    w.writerow(header)\n",
    "\n",
    "# find pose_2d files\n",
    "pose_files = sorted(glob.glob(f\"{DATA_DIR}/mmfit_videos/mm-fit/mm-fit/w*/w*_pose_2d.npy\"))\n",
    "print('Found pose_2d files:', len(pose_files))\n",
    "\n",
    "if pose_files:\n",
    "    sample = pose_files[0]\n",
    "    schema = infer_schema_from_npy(sample)\n",
    "    assert schema in ('coco17','openpose25'), f\"Unknown schema for {sample}\"\n",
    "    mapping = build_mapping(schema)\n",
    "    out_csv = f\"{LANDMARKS_DIR}/mmfit_pose2d_landmarks.csv\"\n",
    "    os.makedirs(LANDMARKS_DIR, exist_ok=True)\n",
    "    with open(out_csv,'w',newline='',encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        write_header(w)\n",
    "        for p in pose_files:\n",
    "            arr = np.load(p)\n",
    "            if arr.ndim == 2:\n",
    "                T,twoK = arr.shape\n",
    "                arr = arr.reshape(T, twoK//2, 2)\n",
    "            T,K,_ = arr.shape\n",
    "            video_id = os.path.basename(os.path.dirname(p))  # wXX\n",
    "            ts = 0.0\n",
    "            for t in range(0,T,2):  # stride=2\n",
    "                row=[video_id,t,ts,1,1]\n",
    "                lm=[None]*(BLAZEPOSE_SIZE*4)\n",
    "                for src_idx,tgt_idx in mapping.items():\n",
    "                    if src_idx < K:\n",
    "                        x,y = float(arr[t,src_idx,0]), float(arr[t,src_idx,1])\n",
    "                        off=tgt_idx*4\n",
    "                        lm[off+0]=x; lm[off+1]=y; lm[off+2]=0.0; lm[off+3]=1.0\n",
    "                row+=lm\n",
    "                w.writerow(row)\n",
    "                ts+=33.33\n",
    "    print('Saved:', out_csv)\n",
    "else:\n",
    "    print('No pose_2d.npy files found; skip Option B.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094baf27",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering\n",
    "Reads a landmarks CSV (from Option A or B) and computes per-frame features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, math, os\n",
    "\n",
    "# choose the landmarks CSV to use\n",
    "lm_csv_a = f\"{LANDMARKS_DIR}/mmfit_videos_landmarks.csv\"\n",
    "lm_csv_b = f\"{LANDMARKS_DIR}/mmfit_pose2d_landmarks.csv\"\n",
    "LANDMARK_CSV = lm_csv_b if os.path.exists(lm_csv_b) else lm_csv_a\n",
    "print('Using landmarks:', LANDMARK_CSV)\n",
    "\n",
    "# Helpers\n",
    "IDX = {'nose':0,'l_sh':11,'r_sh':12,'l_el':13,'r_el':14,'l_wr':15,'r_wr':16,'l_hip':23,'r_hip':24,'l_knee':25,'r_knee':26,'l_ank':27,'r_ank':28}\n",
    "\n",
    "def angle_between(a,b,c):\n",
    "    ba = a-b; bc = c-b\n",
    "    if np.any(np.isnan(ba)) or np.any(np.isnan(bc)):\n",
    "        return np.nan\n",
    "    nba, nbc = np.linalg.norm(ba), np.linalg.norm(bc)\n",
    "    if nba==0 or nbc==0:\n",
    "        return np.nan\n",
    "    cosang = float(np.dot(ba,bc)/(nba*nbc))\n",
    "    cosang = max(-1.0,min(1.0,cosang))\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "\n",
    "df = pd.read_csv(LANDMARK_CSV)\n",
    "if 'lm0_x' in df.columns:\n",
    "    df = df.dropna(subset=['lm0_x']).reset_index(drop=True)\n",
    "\n",
    "rows=[]\n",
    "for _,row in df.iterrows():\n",
    "    w,h = float(row['width']), float(row['height'])\n",
    "    pts = np.full((33,3), np.nan, dtype=float)\n",
    "    for i in range(33):\n",
    "        x = row.get(f'lm{i}_x', np.nan); y = row.get(f'lm{i}_y', np.nan); z = row.get(f'lm{i}_z', np.nan)\n",
    "        if not (pd.isna(x) or pd.isna(y)):\n",
    "            # If pose2d had width/height=1, keep as-is; otherwise scale by frame dims\n",
    "            if w>1 and h>1:\n",
    "                x *= w; y *= h\n",
    "            pts[i] = (x,y, z if not pd.isna(z) else 0.0)\n",
    "    # angles\n",
    "    l_elbow = angle_between(pts[IDX['l_sh']], pts[IDX['l_el']], pts[IDX['l_wr']])\n",
    "    r_elbow = angle_between(pts[IDX['r_sh']], pts[IDX['r_el']], pts[IDX['r_wr']])\n",
    "    l_knee = angle_between(pts[IDX['l_hip']], pts[IDX['l_knee']], pts[IDX['l_ank']])\n",
    "    r_knee = angle_between(pts[IDX['r_hip']], pts[IDX['r_knee']], pts[IDX['r_ank']])\n",
    "    l_hip = angle_between(pts[IDX['l_sh']], pts[IDX['l_hip']], pts[IDX['l_knee']])\n",
    "    r_hip = angle_between(pts[IDX['r_sh']], pts[IDX['r_hip']], pts[IDX['r_knee']])\n",
    "\n",
    "    mid_hip = (pts[IDX['l_hip']]+pts[IDX['r_hip']])/2.0\n",
    "    nose = pts[IDX['nose']]\n",
    "    body_tilt = math.degrees(math.atan2(nose[1]-mid_hip[1], nose[0]-mid_hip[0])) if not (np.any(np.isnan(nose)) or np.any(np.isnan(mid_hip))) else np.nan\n",
    "\n",
    "    def dist(a,b):\n",
    "        if np.any(np.isnan(a[:2])) or np.any(np.isnan(b[:2])):\n",
    "            return np.nan\n",
    "        return float(np.linalg.norm(a[:2]-b[:2]))\n",
    "\n",
    "    shoulder_width = dist(pts[IDX['l_sh']], pts[IDX['r_sh']])\n",
    "    hip_width = dist(pts[IDX['l_hip']], pts[IDX['r_hip']])\n",
    "    torso_len = dist((pts[IDX['l_sh']]+pts[IDX['r_sh']])/2.0, mid_hip)\n",
    "    arm_len = dist(pts[IDX['l_sh']], pts[IDX['l_wr']])\n",
    "\n",
    "    ratio_sh_hip = shoulder_width/(hip_width+1e-6) if not (pd.isna(shoulder_width) or pd.isna(hip_width)) else np.nan\n",
    "    ratio_arm_torso = arm_len/(torso_len+1e-6) if not (pd.isna(arm_len) or pd.isna(torso_len)) else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        'video': row['video'], 'frame': int(row['frame']), 'timestamp': float(row['timestamp']),\n",
    "        'l_elbow': l_elbow, 'r_elbow': r_elbow,\n",
    "        'l_knee': l_knee, 'r_knee': r_knee,\n",
    "        'l_hip': l_hip, 'r_hip': r_hip,\n",
    "        'body_tilt': body_tilt,\n",
    "        'ratio_sh_hip': ratio_sh_hip,\n",
    "        'ratio_arm_torso': ratio_arm_torso,\n",
    "        'shoulder_width': shoulder_width,\n",
    "        'hip_width': hip_width,\n",
    "    })\n",
    "\n",
    "feat_df = pd.DataFrame(rows)\n",
    "FEAT_PKL = f\"{FEATURES_DIR}/mmfit_features.pkl\"\n",
    "feat_df.to_pickle(FEAT_PKL)\n",
    "print('Saved features:', FEAT_PKL, feat_df.shape)\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45073bfb",
   "metadata": {},
   "source": [
    "## 8. Create Windows and Labels\n",
    "Ensure you have a label CSV at `data/video_labels.csv` with columns: video,exercise,form (e.g., `w00,squat,correct`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301970d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "labels_csv = f\"{DATA_DIR}/video_labels.csv\"\n",
    "if not os.path.exists(labels_csv):\n",
    "    with open(labels_csv,'w') as f:\n",
    "        f.write('video,exercise,form\\n')\n",
    "        f.write('w00,squat,correct\\n')\n",
    "        f.write('w01,biceps,incorrect\\n')\n",
    "    print('Created a sample labels CSV at', labels_csv)\n",
    "\n",
    "feat_df = pd.read_pickle(f\"{FEATURES_DIR}/mmfit_features.pkl\")\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "FPS = 30\n",
    "WINDOW_SEC = 1.5\n",
    "WINDOW_SIZE = int(WINDOW_SEC * FPS / 2)  # sample_rate=2 if from videos; same stride used in pose2d conversion\n",
    "STEP = max(1, WINDOW_SIZE//2)\n",
    "\n",
    "rows=[]\n",
    "num_cols=['l_elbow','r_elbow','l_knee','r_knee','l_hip','r_hip','body_tilt','ratio_sh_hip','ratio_arm_torso']\n",
    "for video,vdf in feat_df.groupby('video'):\n",
    "    vdf=vdf.sort_values('frame').reset_index(drop=True)\n",
    "    for start in range(0, len(vdf)-WINDOW_SIZE+1, STEP):\n",
    "        win=vdf.iloc[start:start+WINDOW_SIZE]\n",
    "        agg={'video': video, 'start_frame': int(win.iloc[0]['frame'])}\n",
    "        for c in num_cols:\n",
    "            agg[f'{c}_mean']=float(win[c].mean())\n",
    "            agg[f'{c}_std']=float(win[c].std())\n",
    "            agg[f'{c}_min']=float(win[c].min())\n",
    "            agg[f'{c}_max']=float(win[c].max())\n",
    "        rows.append(agg)\n",
    "\n",
    "win_df = pd.DataFrame(rows)\n",
    "win_df = win_df.merge(labels_df, on='video', how='left')\n",
    "WIN_PKL = f\"{FEATURES_DIR}/mmfit_windows.pkl\"\n",
    "win_df.to_pickle(WIN_PKL)\n",
    "print('Saved windows:', WIN_PKL, win_df.shape)\n",
    "win_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1adc98",
   "metadata": {},
   "source": [
    "## 9. Train Models and Visualize\n",
    "Trains RandomForest baseline vs enhanced and saves confusion matrices to `results/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916671da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns, matplotlib.pyplot as plt, os\n",
    "\n",
    "WIN_PKL = f\"{FEATURES_DIR}/mmfit_windows.pkl\"\n",
    "df = pd.read_pickle(WIN_PKL)\n",
    "\n",
    "df = df.dropna(subset=['exercise']).reset_index(drop=True)\n",
    "le = LabelEncoder()\n",
    "df['y'] = le.fit_transform(df['exercise'])\n",
    "\n",
    "videos = df['video'].unique()\n",
    "train_vids, test_vids = train_test_split(videos, test_size=0.2, random_state=42)\n",
    "train_df = df[df['video'].isin(train_vids)]\n",
    "test_df = df[df['video'].isin(test_vids)]\n",
    "\n",
    "baseline_cols = ['l_elbow_mean','r_elbow_mean','l_knee_mean','r_knee_mean','l_hip_mean','r_hip_mean']\n",
    "enhanced_cols = baseline_cols + ['body_tilt_mean','ratio_sh_hip_mean','ratio_arm_torso_mean'] + [c for c in df.columns if c.endswith('_std')]\n",
    "\n",
    "# Train baseline\n",
    "Xb_tr = train_df[baseline_cols].fillna(0); y_tr = train_df['y']\n",
    "Xb_te = test_df[baseline_cols].fillna(0); y_te = test_df['y']\n",
    "rf_b = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_b.fit(Xb_tr, y_tr)\n",
    "yp_b = rf_b.predict(Xb_te)\n",
    "print('Baseline report\\n', classification_report(y_te, yp_b, target_names=le.classes_))\n",
    "\n",
    "# Train enhanced\n",
    "Xe_tr = train_df[enhanced_cols].fillna(0)\n",
    "Xe_te = test_df[enhanced_cols].fillna(0)\n",
    "rf_e = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_e.fit(Xe_tr, y_tr)\n",
    "yp_e = rf_e.predict(Xe_te)\n",
    "print('Enhanced report\\n', classification_report(y_te, yp_e, target_names=le.classes_))\n",
    "\n",
    "# Save confusion matrices\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "cm_b = confusion_matrix(y_te, yp_b)\n",
    "cm_e = confusion_matrix(y_te, yp_e)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); sns.heatmap(cm_b, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_); plt.title('Baseline')\n",
    "plt.subplot(1,2,2); sns.heatmap(cm_e, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_); plt.title('Enhanced')\n",
    "plt.tight_layout()\n",
    "out_png = f\"{RESULTS_DIR}/confusion_comparison.png\"\n",
    "plt.savefig(out_png, dpi=200)\n",
    "print('Saved figure:', out_png)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d25bc1",
   "metadata": {},
   "source": [
    "## 10. Rep Counting Demo\n",
    "Counts reps using simple thresholds over angle sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa75c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feat_df = pd.read_pickle(f\"{FEATURES_DIR}/mmfit_features.pkl\")\n",
    "\n",
    "# Example: count biceps reps via left elbow angle thresholds\n",
    "v = feat_df['video'].iloc[0] if len(feat_df)>0 else None\n",
    "if v is not None:\n",
    "    vdf = feat_df[feat_df['video']==v].sort_values('frame')\n",
    "    ang = vdf['l_elbow'].fillna(method='ffill').fillna(method='bfill').values\n",
    "    state='up'; reps=0\n",
    "    for a in ang:\n",
    "        if state=='up' and a<50:\n",
    "            state='down'\n",
    "        elif state=='down' and a>160:\n",
    "            state='up'; reps+=1\n",
    "    print(f'Estimated reps for {v}:', reps)\n",
    "else:\n",
    "    print('No features found; ensure earlier steps ran.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb94e5",
   "metadata": {},
   "source": [
    "## 11. Persist Results and Artifacts\n",
    "List outputs and optionally zip them for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40299442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!ls -R {RESULTS_DIR} {MODELS_DIR} {FEATURES_DIR} {LANDMARKS_DIR}\n",
    "# Optional: create a bundle\n",
    "#!zip -r {BASE_DIR}/results_bundle.zip {RESULTS_DIR} {MODELS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d8fa2",
   "metadata": {},
   "source": [
    "## 12. Session Info and Reproducibility\n",
    "Record the environment and freeze packages for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4039a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, os\n",
    "print(sys.version)\n",
    "print(platform.platform())\n",
    "!pip freeze | tee {BASE_DIR}/requirements_colab.txt\n",
    "print('Saved requirements to', f'{BASE_DIR}/requirements_colab.txt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
